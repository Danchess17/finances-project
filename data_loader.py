import pandas as pd
import yfinance as yf
import requests
from datetime import datetime
import warnings
import os

warnings.filterwarnings('ignore')

class DataLoader:
    """ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸"""
    
    def __init__(self, data_dir="data"):
        self.portfolio_data = None
        self.data_dir = data_dir
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ğ°Ğ¿ĞºĞ¸ Ğ´Ğ»Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, ĞµÑĞ»Ğ¸ Ğ¸Ñ… Ğ½ĞµÑ‚
        os.makedirs(data_dir, exist_ok=True)
        os.makedirs(os.path.join(data_dir, "portfolio"), exist_ok=True)
        os.makedirs(os.path.join(data_dir, "individual"), exist_ok=True)
    
    def _generate_filename(self, tickers, real_start_date, real_end_date, file_type="portfolio"):
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ¥ Ğ´Ğ°Ñ‚ Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        
        Parameters:
        -----------
        tickers : list
            Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚Ğ¸ĞºĞµÑ€Ğ¾Ğ²
        real_start_date : datetime
            Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ°Ñ‚Ğ° Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        real_end_date : datetime
            Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ°Ñ ĞºĞ¾Ğ½ĞµÑ‡Ğ½Ğ°Ñ Ğ´Ğ°Ñ‚Ğ° Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        file_type : str
            Ğ¢Ğ¸Ğ¿ Ñ„Ğ°Ğ¹Ğ»Ğ° ('portfolio' Ğ¸Ğ»Ğ¸ 'individual')
        """
        tickers_str = "_".join(tickers)
        start_clean = real_start_date.strftime("%Y%m%d")
        end_clean = real_end_date.strftime("%Y%m%d")
        
        if file_type == "portfolio":
            return f"portfolio/{tickers_str}_{start_clean}_{end_clean}_yf.csv"
        else:
            return f"individual/{tickers_str}_{start_clean}_{end_clean}_yf.csv"
    
    def _generate_individual_filename(self, ticker, real_start_date, real_end_date):
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ñ‚"""
        start_clean = real_start_date.strftime("%Y%m%d")
        end_clean = real_end_date.strftime("%Y%m%d")
        return f"individual/{ticker}_{start_clean}_{end_clean}_yf.csv"
    
    def _get_real_dates(self, portfolio_data):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¸ Ğ¾ĞºĞ¾Ğ½Ñ‡Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
        if not portfolio_data:
            return None, None
        
        real_start_dates = []
        real_end_dates = []
        
        for ticker, data in portfolio_data.items():
            if not data.empty:
                real_start_dates.append(data.index.min())
                real_end_dates.append(data.index.max())
        
        if not real_start_dates:
            return None, None
            
        # Ğ‘ĞµÑ€ĞµĞ¼ ÑĞ°Ğ¼ÑƒÑ Ğ¿Ğ¾Ğ·Ğ´Ğ½ÑÑ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ´Ğ°Ñ‚Ñƒ Ğ¸ ÑĞ°Ğ¼ÑƒÑ Ñ€Ğ°Ğ½Ğ½ÑÑ ĞºĞ¾Ğ½ĞµÑ‡Ğ½ÑƒÑ
        # Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´, Ğ³Ğ´Ğµ ĞµÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ğ°ĞºÑ†Ğ¸ÑĞ¼
        common_start = max(real_start_dates)
        common_end = min(real_end_dates)
        
        return common_start, common_end
    
    def _get_individual_dates(self, data):
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸"""
        if data.empty:
            return None, None
        return data.index.min(), data.index.max()
    
    def _save_portfolio_to_csv(self, portfolio_data, tickers, requested_start_date, requested_end_date):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ² CSV Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ¼ĞµĞ½Ğ°Ğ¼Ğ¸"""
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ Ğ•ĞĞ›Ğ¬ĞĞ«Ğ• Ğ´Ğ°Ñ‚Ñ‹ Ğ¸Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        real_start_date, real_end_date = self._get_real_dates(portfolio_data)
        
        if not real_start_date or not real_end_date:
            print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ")
            return None
        
        filename = self._generate_filename(tickers, real_start_date, real_end_date, "portfolio")
        filepath = os.path.join(self.data_dir, filename)
        
        try:
            if not portfolio_data:
                return None
                
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ DataFrame Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ¼
            first_ticker = list(portfolio_data.keys())[0]
            index_dates = portfolio_data[first_ticker].index
            all_data = pd.DataFrame(index=index_dates)
            
            for ticker, data in portfolio_data.items():
                for column in ['High', 'Low', 'Close', 'Volume']:
                    if column in data.columns:
                        all_data[f"{ticker}_{column}"] = data[column]
            
            all_data.to_csv(filepath, encoding='utf-8')
            
            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ñƒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸
            requested_start = datetime.strptime(requested_start_date, '%Y-%m-%d')
            requested_end = datetime.strptime(requested_end_date, '%Y-%m-%d')
            
            print(f"âœ“ ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: {filepath}")
            print(f"  ğŸ“… Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´: {requested_start_date} - {requested_end_date}")
            print(f"  ğŸ“Š Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´: {real_start_date.strftime('%Y-%m-%d')} - {real_end_date.strftime('%Y-%m-%d')}")
            
            # ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ ĞµÑĞ»Ğ¸ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñ‹ Ğ½Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ÑÑ‚
            if real_start_date > requested_start or real_end_date < requested_end:
                print(f"  âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğ¼!")
                
            return filepath
            
        except Exception as e:
            print(f"âœ— ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ Ğ² CSV: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _save_individual_to_csv(self, portfolio_data, requested_start_date, requested_end_date):
        """Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾ Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ¼ĞµĞ½Ğ°Ğ¼Ğ¸"""
        saved_files = []
        
        for ticker, data in portfolio_data.items():
            try:
                # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹ Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸
                real_start_date, real_end_date = self._get_individual_dates(data)
                
                if not real_start_date or not real_end_date:
                    continue
                
                filename = self._generate_individual_filename(ticker, real_start_date, real_end_date)
                filepath = os.path.join(self.data_dir, filename)
                
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸
                data.to_csv(filepath, encoding='utf-8')
                saved_files.append(filepath)
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ñƒ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸
                requested_start = datetime.strptime(requested_start_date, '%Y-%m-%d')
                requested_end = datetime.strptime(requested_end_date, '%Y-%m-%d')
                
                print(f"âœ“ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ {ticker} ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: {filepath}")
                print(f"  ğŸ“… Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´: {requested_start_date} - {requested_end_date}")
                print(f"  ğŸ“Š Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´: {real_start_date.strftime('%Y-%m-%d')} - {real_end_date.strftime('%Y-%m-%d')}")
                
                # ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğµ ĞµÑĞ»Ğ¸ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ñ‹ Ğ½Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ÑÑ‚
                if real_start_date > requested_start or real_end_date < requested_end:
                    print(f"  âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğ¼!")
                
            except Exception as e:
                print(f"âœ— ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ {ticker} Ğ² CSV: {e}")
        
        return saved_files
    
    def _load_from_csv(self, tickers, start_date, end_date):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· CSV Ñ„Ğ°Ğ¹Ğ»Ğ°"""
        # Ğ”Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹ Ğ¸Ğ· Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°
        # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ñ„Ğ°Ğ¹Ğ» Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸
        tickers_str = "_".join(tickers)
        start_clean = start_date.replace("-", "")
        end_clean = end_date.replace("-", "")
        
        # Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 1: Ñ„Ğ°Ğ¹Ğ» Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ñ‚Ğ°Ğ¼Ğ¸ (ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)
        filename_old = f"portfolio/{tickers_str}_{start_clean}_{end_clean}_yf.csv"
        filepath_old = os.path.join(self.data_dir, filename_old)
        
        # Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ 2: Ñ„Ğ°Ğ¹Ğ» Ğ² ĞºĞ¾Ñ€Ğ½Ğµ (ÑÑ‚Ğ°Ñ€Ğ¾Ğµ Ñ€Ğ°ÑĞ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ)
        filename_root = f"{tickers_str}_{start_clean}_{end_clean}_yf.csv"
        filepath_root = os.path.join(self.data_dir, filename_root)
        
        filepath = None
        if os.path.exists(filepath_old):
            filepath = filepath_old
        elif os.path.exists(filepath_root):
            filepath = filepath_root
        
        if not filepath:
            return None
            
        try:
            print(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· ĞºÑÑˆĞ°: {filepath}")
            combined_df = pd.read_csv(filepath, index_col=0, parse_dates=True)
            
            # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ portfolio_data
            portfolio_data = {}
            for ticker in tickers:
                ticker_data = {}
                for column in ['High', 'Low', 'Close', 'Volume']:
                    col_name = f"{ticker}_{column}"
                    if col_name in combined_df.columns:
                        ticker_data[column] = combined_df[col_name]
                
                if ticker_data:
                    ticker_df = pd.DataFrame(ticker_data, index=combined_df.index)
                    portfolio_data[ticker] = ticker_df
            
            self.portfolio_data = portfolio_data
            
            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹ Ğ¸Ğ· Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
            real_start, real_end = self._get_real_dates(portfolio_data)
            if real_start and real_end:
                print(f"  ğŸ“Š Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ Ğ² Ñ„Ğ°Ğ¹Ğ»Ğµ: {real_start.strftime('%Y-%m-%d')} - {real_end.strftime('%Y-%m-%d')}")
            
            return portfolio_data
            
        except Exception as e:
            print(f"âœ— ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ Ğ¸Ğ· CSV: {e}")
            return None
    
    def _load_individual_from_csv(self, tickers, start_date, end_date):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾"""
        portfolio_data = {}
        loaded_tickers = []
        
        for ticker in tickers:
            # Ğ”Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹
            start_clean = start_date.replace("-", "")
            end_clean = end_date.replace("-", "")
            filename = f"individual/{ticker}_{start_clean}_{end_clean}_yf.csv"
            filepath = os.path.join(self.data_dir, filename)
            
            if not os.path.exists(filepath):
                continue
                
            try:
                print(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {ticker} Ğ¸Ğ· ĞºÑÑˆĞ°: {filepath}")
                individual_data = pd.read_csv(filepath, index_col=0, parse_dates=True)
                portfolio_data[ticker] = individual_data
                loaded_tickers.append(ticker)
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹
                real_start, real_end = self._get_individual_dates(individual_data)
                if real_start and real_end:
                    print(f"  ğŸ“Š Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´: {real_start.strftime('%Y-%m-%d')} - {real_end.strftime('%Y-%m-%d')}")
                
            except Exception as e:
                print(f"âœ— ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ {ticker} Ğ¸Ğ· CSV: {e}")
        
        if portfolio_data:
            self.portfolio_data = portfolio_data
            return portfolio_data
        else:
            return None
    
    def fetch_data(self, tickers, start_date, end_date, source='yfinance', use_cache=True, save_individual=True):
        """
        Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ğ¼ Ñ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ² CSV
        
        Parameters:
        -----------
        tickers : list
            Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚Ğ¸ĞºĞµÑ€Ğ¾Ğ² Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¾Ğ²
        start_date : str
            ĞĞ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ´Ğ°Ñ‚Ğ° Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ 'YYYY-MM-DD'
        end_date : str
            ĞšĞ¾Ğ½ĞµÑ‡Ğ½Ğ°Ñ Ğ´Ğ°Ñ‚Ğ° Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ 'YYYY-MM-DD'
        source : str
            Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ('yfinance', 'moex')
        use_cache : bool
            Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹
        save_individual : bool
            Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾
        """
        
        # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¸Ğ· ĞºÑÑˆĞ°
        if use_cache:
            cached_data = self._load_from_csv(tickers, start_date, end_date)
            if cached_data is not None:
                return cached_data
            
            # Ğ•ÑĞ»Ğ¸ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ Ğ½ĞµÑ‚, Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
            cached_data = self._load_individual_from_csv(tickers, start_date, end_date)
            if cached_data is not None:
                print("âœ“ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ñ‹ Ğ¸Ğ· Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²")
                return cached_data
        
        print("Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Yahoo Finance...")
        data = {}
        successful_tickers = []
        
        if source == 'yfinance':
            for ticker in tickers:
                try:
                    stock = yf.download(ticker, start=start_date, end=end_date, progress=False)
                    if not stock.empty:
                        data[ticker] = stock[['High', 'Low', 'Close', 'Volume']]
                        successful_tickers.append(ticker)
                        print(f"âœ“ {ticker}: {len(stock)} Ğ´Ğ½ĞµĞ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
                    else:
                        print(f"âœ— {ticker}: Ğ½ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
                except Exception as e:
                    print(f"âœ— {ticker}: {e}")
        
        if data:
            self.portfolio_data = data
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ¼ĞµĞ½Ğ°Ğ¼Ğ¸!)
            self._save_portfolio_to_csv(data, successful_tickers, start_date, end_date)
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (ĞµÑĞ»Ğ¸ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾)
            if save_individual:
                self._save_individual_to_csv(data, start_date, end_date)
        
        return data
    
    def load_individual_ticker(self, ticker, start_date, end_date, use_cache=True):
        """
        Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ñ‚Ğ¸ĞºĞµÑ€Ñƒ
        """
        # Ğ”Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑˆĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹
        start_clean = start_date.replace("-", "")
        end_clean = end_date.replace("-", "")
        filename = f"individual/{ticker}_{start_clean}_{end_clean}_yf.csv"
        filepath = os.path.join(self.data_dir, filename)
        
        if use_cache and os.path.exists(filepath):
            try:
                print(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {ticker} Ğ¸Ğ· ĞºÑÑˆĞ°: {filepath}")
                data = pd.read_csv(filepath, index_col=0, parse_dates=True)
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹
                real_start, real_end = self._get_individual_dates(data)
                if real_start and real_end:
                    print(f"  ğŸ“Š Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´: {real_start.strftime('%Y-%m-%d')} - {real_end.strftime('%Y-%m-%d')}")
                    
                return data
            except Exception as e:
                print(f"âœ— ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ {ticker} Ğ¸Ğ· CSV: {e}")
        
        # Ğ•ÑĞ»Ğ¸ ĞºÑÑˆĞ° Ğ½ĞµÑ‚ Ğ¸Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¸Ğ· Yahoo Finance
        print(f"Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {ticker} Ğ¸Ğ· Yahoo Finance...")
        try:
            stock = yf.download(ticker, start=start_date, end=end_date, progress=False)
            if not stock.empty:
                data = stock[['High', 'Low', 'Close', 'Volume']]
                
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² ĞºÑÑˆ Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸Ğ¼ĞµĞ½ĞµĞ¼
                real_start, real_end = self._get_individual_dates(data)
                if real_start and real_end:
                    filename = self._generate_individual_filename(ticker, real_start, real_end)
                    filepath = os.path.join(self.data_dir, filename)
                    
                    try:
                        data.to_csv(filepath, encoding='utf-8')
                        print(f"âœ“ Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ {ticker} ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: {filepath}")
                        print(f"  ğŸ“Š Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´: {real_start.strftime('%Y-%m-%d')} - {real_end.strftime('%Y-%m-%d')}")
                    except Exception as e:
                        print(f"âœ— ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ {ticker} Ğ² CSV: {e}")
                
                return data
            else:
                print(f"âœ— {ticker}: Ğ½ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…")
                return None
                
        except Exception as e:
            print(f"âœ— {ticker}: {e}")
            return None
    
    def get_common_period(self):
        """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¾Ğ±Ñ‰Ğ¸Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ°ĞºÑ‚Ğ¸Ğ²Ğ¾Ğ²"""
        if not self.portfolio_data:
            return None
            
        common_start = None
        common_end = None
        
        for ticker, data in self.portfolio_data.items():
            if data.empty:
                continue
                
            start = data.index.min()
            end = data.index.max()
            
            if common_start is None or start > common_start:
                common_start = start
            if common_end is None or end < common_end:
                common_end = end
        
        return common_start, common_end

    def list_saved_datasets(self):
        """ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ²ÑĞµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñ‹"""
        if not os.path.exists(self.data_dir):
            print("ĞŸĞ°Ğ¿ĞºĞ° Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚!")
            return []
        
        print("\nğŸ“ Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞĞ«Ğ• Ğ”ĞĞĞĞ«Ğ•:")
        
        # ĞŸĞ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        portfolio_dir = os.path.join(self.data_dir, "portfolio")
        if os.path.exists(portfolio_dir):
            portfolio_files = [f for f in os.listdir(portfolio_dir) if f.endswith('.csv')]
            print(f"\nğŸ¯ ĞŸĞĞ Ğ¢Ğ¤Ğ•Ğ›Ğ˜ ({len(portfolio_files)}):")
            for file in sorted(portfolio_files):
                file_path = os.path.join(portfolio_dir, file)
                file_size = os.path.getsize(file_path) / 1024
                print(f"  ğŸ“Š {file} ({file_size:.1f} KB)")
        
        # Ğ˜Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
        individual_dir = os.path.join(self.data_dir, "individual")
        if os.path.exists(individual_dir):
            individual_files = [f for f in os.listdir(individual_dir) if f.endswith('.csv')]
            print(f"\nğŸ“ˆ Ğ˜ĞĞ”Ğ˜Ğ’Ğ˜Ğ”Ğ£ĞĞ›Ğ¬ĞĞ«Ğ• ĞĞšĞ¦Ğ˜Ğ˜ ({len(individual_files)}):")
            
            # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ñ‚Ğ¸ĞºĞµÑ€Ğ°Ğ¼
            ticker_files = {}
            for file in individual_files:
                ticker = file.split('_')[0]
                if ticker not in ticker_files:
                    ticker_files[ticker] = []
                ticker_files[ticker].append(file)
            
            for ticker, files in sorted(ticker_files.items()):
                print(f"  {ticker}: {len(files)} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²")
                for file in sorted(files):
                    file_path = os.path.join(individual_dir, file)
                    file_size = os.path.getsize(file_path) / 1024
                    print(f"    ğŸ“„ {file} ({file_size:.1f} KB)")

# ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
if __name__ == "__main__":
    loader = DataLoader()
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸Ğ½Ğ´Ğ¸Ğ²Ğ¸Ğ´ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
    print("=== Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ ĞŸĞĞ Ğ¢Ğ¤Ğ•Ğ›Ğ¯ ===")
    portfolio_data = loader.fetch_data(
        tickers=['AAPL', 'MSFT', 'GOOGL'],
        start_date='2013-01-01',
        end_date='2025-11-17',
        save_individual=True
    )
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ°ĞºÑ†Ğ¸Ğ¸ (Ñ€Ğ¾ÑÑĞ¸Ğ¹ÑĞºĞ°Ñ - Ğ¿Ğ¾ĞºĞ°Ğ¶ĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ñ‚Ñ‹)
    print("\n=== Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ ĞĞ¢Ğ”Ğ•Ğ›Ğ¬ĞĞĞ™ ĞĞšĞ¦Ğ˜Ğ˜ ===")
    sber_data = loader.load_individual_ticker(
        ticker='SBER.ME',
        start_date='2013-01-01',
        end_date='2025-11-17'
    )
    
    # ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
    print("\n=== Ğ¡ĞŸĞ˜Ğ¡ĞĞš Ğ¤ĞĞ™Ğ›ĞĞ’ ===")
    loader.list_saved_datasets()