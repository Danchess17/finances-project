import pandas as pd
import yfinance as yf
import requests
from datetime import datetime
import warnings
import os

warnings.filterwarnings('ignore')

class DataLoader:
    """ÐšÐ»Ð°ÑÑ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸"""
    
    def __init__(self, data_dir="data"):
        self.portfolio_data = None
        self.data_dir = data_dir
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¿ÐºÐ¸ Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…, ÐµÑÐ»Ð¸ Ð¸Ñ… Ð½ÐµÑ‚
        os.makedirs(data_dir, exist_ok=True)
        os.makedirs(os.path.join(data_dir, "portfolio"), exist_ok=True)
        os.makedirs(os.path.join(data_dir, "individual"), exist_ok=True)
    
    def _generate_portfolio_filename(self, tickers, start_date, end_date):
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð»Ñ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»Ñ"""
        tickers_str = "_".join(tickers)
        start_clean = start_date.replace("-", "")
        end_clean = end_date.replace("-", "")
        return f"portfolio/{tickers_str}_{start_clean}_{end_clean}_yf.csv"
    
    def _generate_individual_filename(self, ticker, start_date, end_date):
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð»Ñ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð°ÐºÑ†Ð¸Ð¸"""
        start_clean = start_date.replace("-", "")
        end_clean = end_date.replace("-", "")
        return f"individual/{ticker}_{start_clean}_{end_clean}_yf.csv"
    
    def _save_portfolio_to_csv(self, portfolio_data, tickers, start_date, end_date):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð² CSV"""
        filename = self._generate_portfolio_filename(tickers, start_date, end_date)
        filepath = os.path.join(self.data_dir, filename)
        
        try:
            if not portfolio_data:
                return None
                
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ DataFrame Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ Ð¸Ð½Ð´ÐµÐºÑÐ¾Ð¼
            first_ticker = list(portfolio_data.keys())[0]
            index_dates = portfolio_data[first_ticker].index
            all_data = pd.DataFrame(index=index_dates)
            
            for ticker, data in portfolio_data.items():
                for column in ['High', 'Low', 'Close', 'Volume']:
                    if column in data.columns:
                        all_data[f"{ticker}_{column}"] = data[column]
            
            all_data.to_csv(filepath, encoding='utf-8')
            print(f"âœ“ ÐŸÐ¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»Ñ Ð² CSV: {e}")
            return None
    
    def _save_individual_to_csv(self, portfolio_data, start_date, end_date):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð°ÐºÑ†Ð¸Ð¸ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾"""
        saved_files = []
        
        for ticker, data in portfolio_data.items():
            try:
                filename = self._generate_individual_filename(ticker, start_date, end_date)
                filepath = os.path.join(self.data_dir, filename)
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ð´Ð½Ð¾Ð¹ Ð°ÐºÑ†Ð¸Ð¸
                data.to_csv(filepath, encoding='utf-8')
                saved_files.append(filepath)
                print(f"âœ“ Ð”Ð°Ð½Ð½Ñ‹Ðµ {ticker} ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {filepath}")
                
            except Exception as e:
                print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ {ticker} Ð² CSV: {e}")
        
        return saved_files
    
    def _load_portfolio_from_csv(self, tickers, start_date, end_date):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· CSV"""
        filename = self._generate_portfolio_filename(tickers, start_date, end_date)
        filepath = os.path.join(self.data_dir, filename)
        
        if not os.path.exists(filepath):
            return None
            
        try:
            print(f"Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· ÐºÑÑˆÐ°: {filepath}")
            combined_df = pd.read_csv(filepath, index_col=0, parse_dates=True)
            
            # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ portfolio_data
            portfolio_data = {}
            for ticker in tickers:
                ticker_data = {}
                for column in ['High', 'Low', 'Close', 'Volume']:
                    col_name = f"{ticker}_{column}"
                    if col_name in combined_df.columns:
                        ticker_data[column] = combined_df[col_name]
                
                if ticker_data:
                    ticker_df = pd.DataFrame(ticker_data, index=combined_df.index)
                    portfolio_data[ticker] = ticker_df
            
            self.portfolio_data = portfolio_data
            return portfolio_data
            
        except Exception as e:
            print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»Ñ Ð¸Ð· CSV: {e}")
            return None
    
    def _load_individual_from_csv(self, tickers, start_date, end_date):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð°ÐºÑ†Ð¸Ð¸ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾"""
        portfolio_data = {}
        loaded_tickers = []
        
        for ticker in tickers:
            filename = self._generate_individual_filename(ticker, start_date, end_date)
            filepath = os.path.join(self.data_dir, filename)
            
            if not os.path.exists(filepath):
                continue
                
            try:
                print(f"Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… {ticker} Ð¸Ð· ÐºÑÑˆÐ°: {filepath}")
                individual_data = pd.read_csv(filepath, index_col=0, parse_dates=True)
                portfolio_data[ticker] = individual_data
                loaded_tickers.append(ticker)
                
            except Exception as e:
                print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {ticker} Ð¸Ð· CSV: {e}")
        
        if portfolio_data:
            self.portfolio_data = portfolio_data
            return portfolio_data
        else:
            return None
    
    def fetch_data(self, tickers, start_date, end_date, source='yfinance', use_cache=True, save_individual=True):
        """
        Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ Ð°ÐºÑ‚Ð¸Ð²Ð°Ð¼ Ñ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ Ð² CSV
        
        Parameters:
        -----------
        tickers : list
            Ð¡Ð¿Ð¸ÑÐ¾Ðº Ñ‚Ð¸ÐºÐµÑ€Ð¾Ð² Ð°ÐºÑ‚Ð¸Ð²Ð¾Ð²
        start_date : str
            ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð°Ñ‚Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ 'YYYY-MM-DD'
        end_date : str
            ÐšÐ¾Ð½ÐµÑ‡Ð½Ð°Ñ Ð´Ð°Ñ‚Ð° Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ 'YYYY-MM-DD'
        source : str
            Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ… ('yfinance', 'moex')
        use_cache : bool
            Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹
        save_individual : bool
            Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð°ÐºÑ†Ð¸Ð¸ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾
        """
        
        # ÐŸÑ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¸Ð· ÐºÑÑˆÐ° (ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒ, Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ)
        if use_cache:
            # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð²ÐµÑÑŒ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒ
            cached_data = self._load_portfolio_from_csv(tickers, start_date, end_date)
            if cached_data is not None:
                return cached_data
            
            # Ð•ÑÐ»Ð¸ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»Ñ Ð½ÐµÑ‚, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
            cached_data = self._load_individual_from_csv(tickers, start_date, end_date)
            if cached_data is not None:
                print("âœ“ Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹ Ð¸Ð· Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²")
                return cached_data
        
        print("Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· Yahoo Finance...")
        data = {}
        successful_tickers = []
        
        if source == 'yfinance':
            for ticker in tickers:
                try:
                    stock = yf.download(ticker, start=start_date, end=end_date, progress=False)
                    if not stock.empty:
                        data[ticker] = stock[['High', 'Low', 'Close', 'Volume']]
                        successful_tickers.append(ticker)
                        print(f"âœ“ {ticker}: {len(stock)} Ð´Ð½ÐµÐ¹ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
                    else:
                        print(f"âœ— {ticker}: Ð½ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
                except Exception as e:
                    print(f"âœ— {ticker}: {e}")
        
        if data:
            self.portfolio_data = data
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
            self._save_portfolio_to_csv(data, successful_tickers, start_date, end_date)
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ (ÐµÑÐ»Ð¸ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾)
            if save_individual:
                self._save_individual_to_csv(data, start_date, end_date)
        
        return data
    
    def load_individual_ticker(self, ticker, start_date, end_date, use_cache=True):
        """
        Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ñ‚Ð¸ÐºÐµÑ€Ñƒ
        """
        filename = self._generate_individual_filename(ticker, start_date, end_date)
        filepath = os.path.join(self.data_dir, filename)
        
        if use_cache and os.path.exists(filepath):
            try:
                print(f"Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… {ticker} Ð¸Ð· ÐºÑÑˆÐ°: {filepath}")
                data = pd.read_csv(filepath, index_col=0, parse_dates=True)
                return data
            except Exception as e:
                print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {ticker} Ð¸Ð· CSV: {e}")
        
        # Ð•ÑÐ»Ð¸ ÐºÑÑˆÐ° Ð½ÐµÑ‚ Ð¸Ð»Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐ°, Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸Ð· Yahoo Finance
        print(f"Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… {ticker} Ð¸Ð· Yahoo Finance...")
        try:
            stock = yf.download(ticker, start=start_date, end=end_date, progress=False)
            if not stock.empty:
                data = stock[['High', 'Low', 'Close', 'Volume']]
                
                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² ÐºÑÑˆ
                try:
                    data.to_csv(filepath, encoding='utf-8')
                    print(f"âœ“ Ð”Ð°Ð½Ð½Ñ‹Ðµ {ticker} ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {filepath}")
                except Exception as e:
                    print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ {ticker} Ð² CSV: {e}")
                
                return data
            else:
                print(f"âœ— {ticker}: Ð½ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
                return None
                
        except Exception as e:
            print(f"âœ— {ticker}: {e}")
            return None
    
    def get_common_period(self):
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¾Ð±Ñ‰Ð¸Ð¹ Ð¿ÐµÑ€Ð¸Ð¾Ð´ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð²ÑÐµÑ… Ð°ÐºÑ‚Ð¸Ð²Ð¾Ð²"""
        if not self.portfolio_data:
            return None
            
        common_start = None
        common_end = None
        
        for ticker, data in self.portfolio_data.items():
            if data.empty:
                continue
                
            start = data.index.min()
            end = data.index.max()
            
            if common_start is None or start > common_start:
                common_start = start
            if common_end is None or end < common_end:
                common_end = end
        
        return common_start, common_end

    def list_saved_datasets(self):
        """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð²ÑÐµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ñ‹"""
        if not os.path.exists(self.data_dir):
            print("ÐŸÐ°Ð¿ÐºÐ° Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚!")
            return []
        
        print("\nðŸ“ Ð¡ÐžÐ¥Ð ÐÐÐ•ÐÐÐ«Ð• Ð”ÐÐÐÐ«Ð•:")
        
        # ÐŸÐ¾Ñ€Ñ‚Ñ„ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        portfolio_dir = os.path.join(self.data_dir, "portfolio")
        if os.path.exists(portfolio_dir):
            portfolio_files = [f for f in os.listdir(portfolio_dir) if f.endswith('.csv')]
            print(f"\nðŸŽ¯ ÐŸÐžÐ Ð¢Ð¤Ð•Ð›Ð˜ ({len(portfolio_files)}):")
            for file in sorted(portfolio_files):
                file_path = os.path.join(portfolio_dir, file)
                file_size = os.path.getsize(file_path) / 1024
                print(f"  ðŸ“Š {file} ({file_size:.1f} KB)")
        
        # Ð˜Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        individual_dir = os.path.join(self.data_dir, "individual")
        if os.path.exists(individual_dir):
            individual_files = [f for f in os.listdir(individual_dir) if f.endswith('.csv')]
            print(f"\nðŸ“ˆ Ð˜ÐÐ”Ð˜Ð’Ð˜Ð”Ð£ÐÐ›Ð¬ÐÐ«Ð• ÐÐšÐ¦Ð˜Ð˜ ({len(individual_files)}):")
            
            # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ñ‚Ð¸ÐºÐµÑ€Ð°Ð¼
            ticker_files = {}
            for file in individual_files:
                ticker = file.split('_')[0]
                if ticker not in ticker_files:
                    ticker_files[ticker] = []
                ticker_files[ticker].append(file)
            
            for ticker, files in sorted(ticker_files.items()):
                print(f"  {ticker}: {len(files)} Ñ„Ð°Ð¹Ð»Ð¾Ð²")
                for file in sorted(files):
                    file_path = os.path.join(individual_dir, file)
                    file_size = os.path.getsize(file_path) / 1024
                    print(f"    ðŸ“„ {file} ({file_size:.1f} KB)")

# ÐŸÑ€Ð¸Ð¼ÐµÑ€ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ
if __name__ == "__main__":
    loader = DataLoader()
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿Ð¾Ñ€Ñ‚Ñ„ÐµÐ»Ñ Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸ÐµÐ¼ Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ñ„Ð°Ð¹Ð»Ð¾Ð²
    print("=== Ð—ÐÐ“Ð Ð£Ð—ÐšÐ ÐŸÐžÐ Ð¢Ð¤Ð•Ð›Ð¯ ===")
    portfolio_data = loader.fetch_data(
        tickers=['AAPL', 'MSFT', 'GOOGL'],
        start_date='2023-01-01',
        end_date='2024-01-01',
        save_individual=True  # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÑ‚ÑŒ Ð¸Ð½Ð´Ð¸Ð²Ð¸Ð´ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
    )
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð°ÐºÑ†Ð¸Ð¸
    print("\n=== Ð—ÐÐ“Ð Ð£Ð—ÐšÐ ÐžÐ¢Ð”Ð•Ð›Ð¬ÐÐžÐ™ ÐÐšÐ¦Ð˜Ð˜ ===")
    tsla_data = loader.load_individual_ticker(
        ticker='TSLA',
        start_date='2023-01-01',
        end_date='2024-01-01'
    )
    
    # ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹
    print("\n=== Ð¡ÐŸÐ˜Ð¡ÐžÐš Ð¤ÐÐ™Ð›ÐžÐ’ ===")
    loader.list_saved_datasets()